{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5WSiRrdKWhcgDVnumTfAr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Boyintheorchard/Image_Translator/blob/main/AI_MetaPrep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üì¶ Objective**\n",
        "\n",
        "Build a repeatable, AI-powered workflow to:\n",
        "\n",
        "Process multi-angle bag images\n",
        "\n",
        "Extract and merge metadata from Excel (dimensions, color, style)\n",
        "\n",
        "Generate structured AI descriptions using GPT-4o\n",
        "\n",
        "Output a CSV ready for:\n",
        "\n",
        "Prompt libraries\n",
        "\n",
        "AI image generation (e.g., RunwayML, Veo, Midjourney)\n",
        "\n",
        "Internal QA or cataloging"
      ],
      "metadata": {
        "id": "0OvHCvRI4pzw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "S1vtdl5D5Amh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üõ† Core Tools Used**\n",
        "\n",
        "Google Colab (for development)\n",
        "\n",
        "OpenAI GPT-4o API (for image-to-text)\n",
        "\n",
        "Pandas (data handling)\n",
        "\n",
        "Base64 / PIL (image encoding)\n",
        "\n",
        "Excel metadata sheets with:\n",
        "\n",
        "Article Level: Height/Width/Depth\n",
        "\n",
        "SKU Level: Color\n",
        "\n",
        "SKU Classification: Color Code"
      ],
      "metadata": {
        "id": "b8qJiNSG41oG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Em7Atdnk5CGg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üîÅ Workflow Steps**\n",
        "\n",
        "üìÇ Step 1: Prepare & Upload Files\n",
        "1. Open your local copy of Item Master\n",
        "2. Under **SKU Classification** Sheet/Tab;\n",
        "  1. Change **AQ1** to Colour\n",
        "  2. Change **AR1** to COL\n",
        "  3. Change **AS1** to CODE\n",
        "3. Upload New Item Master .xlsx file (with all metadata sheets)\n",
        "4. Upload ZIP file of bag images\n",
        "\n",
        "üìä Step 2: Extract Metadata `[Code]`\n",
        "\n",
        "Parse image filenames: Article-Insertion-ColourCode-View\n",
        "\n",
        "Merge across 3 sheets: Article, SKU Level, SKU Classification\n",
        "\n",
        "Add Dimensions column (in cm)\n",
        "\n",
        "Clean for duplicates and inconsistent color code matches\n",
        "\n",
        "ü§ñ Step 3: AI Description via GPT-4o `[Code]`\n",
        "\n",
        "Loop through each image\n",
        "\n",
        "Use dimensions + color + view as input context\n",
        "\n",
        "Get back 1-sentence professional descriptions\n",
        "\n",
        "Add column: AI_Description\n",
        "\n",
        "üßæ Step 4: Output\n",
        "Export full CSV as:\n",
        "Preprocessed_Bag_Metadata.csv or Final_Metadata_With_AI_Descriptions.csv\n",
        "\n",
        "Each row includes:\n",
        "\n",
        "Image file\n",
        "\n",
        "Article No, Color, Colour Code, View\n",
        "\n",
        "Dimensions\n",
        "\n",
        "AI Description (GPT-4o)\n",
        "\n"
      ],
      "metadata": {
        "id": "iiEBMfF_5u-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üì¶ Colab Preprocessing Script: Bag Image Metadata Join (Safe Merge Version)\n",
        "import pandas as pd, os, re, zipfile\n",
        "from google.colab import files\n",
        "\n",
        "# ==== STEP 1: Upload Files ====\n",
        "print(\"üóÇ Upload your METADATA Excel (.xlsx) file:\")\n",
        "meta_uploaded = files.upload()\n",
        "meta_path = list(meta_uploaded.keys())[0]\n",
        "\n",
        "print(\"üñº Upload your ZIP of images:\")\n",
        "zip_uploaded = files.upload()\n",
        "zip_path = list(zip_uploaded.keys())[0]\n",
        "\n",
        "# ==== STEP 2: Unzip Images ====\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"images\")\n",
        "\n",
        "image_folder = \"images\"\n",
        "image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "# ==== STEP 3: Parse Filenames ====\n",
        "pattern = re.compile(r\"^(?P<Article>[A-Z]{2}\\d-\\d+)(?:-(?P<Insertion>\\d+))?-(?P<ColourCode>\\d+)-(?P<ViewNo>\\d+)\", re.I)\n",
        "\n",
        "parsed = []\n",
        "for fname in image_files:\n",
        "    m = pattern.match(fname)\n",
        "    parsed.append({\n",
        "        \"Image File\": fname,\n",
        "        \"Article No\": m.group(\"Article\") if m else \"\",\n",
        "        \"Insertion\": m.group(\"Insertion\") if m and m.group(\"Insertion\") else \"\",\n",
        "        \"Colour Code\": m.group(\"ColourCode\") if m else \"\",\n",
        "        \"View No\": m.group(\"ViewNo\") if m else \"\"\n",
        "    })\n",
        "\n",
        "images_df = pd.DataFrame(parsed)\n",
        "\n",
        "# ==== STEP 4: Load Excel Sheets ====\n",
        "xls = pd.ExcelFile(meta_path)\n",
        "\n",
        "# Article Dimensions\n",
        "article_df = pd.read_excel(xls, sheet_name=\"Artlcle Level (R&D)\", header=1)\n",
        "article_df = article_df.rename(columns={\"Article No.\": \"Article No\"})\n",
        "\n",
        "article_dim = article_df[[\"Article No\", \"Height (MM)\", \"Width (MM)\", \"Depth (MM)\"]].dropna(subset=[\"Article No\"])\n",
        "article_dim = article_dim.rename(columns={\n",
        "    \"Height (MM)\": \"Height (cm)\",\n",
        "    \"Width (MM)\": \"Width (cm)\",\n",
        "    \"Depth (MM)\": \"Depth (cm)\"\n",
        "})\n",
        "for col in [\"Height (cm)\", \"Width (cm)\", \"Depth (cm)\"]:\n",
        "    article_dim[col] = pd.to_numeric(article_dim[col], errors=\"coerce\") / 10\n",
        "\n",
        "# SKU Level: Color info\n",
        "sku_df = pd.read_excel(xls, sheet_name=\"SKU Level (R&D)\", header=1)\n",
        "sku_df = sku_df.rename(columns={\"Article No.\": \"Article No\"})\n",
        "sku_df[\"Color\"] = sku_df[\"Color\"].str.strip()\n",
        "\n",
        "# SKU Classification: Color Code info\n",
        "code_df = pd.read_excel(xls, sheet_name=\"SKU Classification\")\n",
        "code_df.columns = code_df.columns.str.strip()\n",
        "code_df = code_df.rename(columns={\"Colour\": \"Color\", \"CODE\": \"Color Code\"})\n",
        "code_df[\"Color\"] = code_df[\"Color\"].str.strip()\n",
        "\n",
        "# ==== STEP 5: Merge Color + Color Code safely ====\n",
        "# Step 1: Merge color with color code\n",
        "# Ensure the index used for mapping is unique\n",
        "code_df_unique_color = code_df.drop_duplicates(subset=[\"Color\"])\n",
        "sku_df[\"Colour Code\"] = sku_df[\"Color\"].map(code_df_unique_color.set_index(\"Color\")[\"Color Code\"])\n",
        "\n",
        "\n",
        "# Step 2: Drop duplicates to avoid many-to-many explosion\n",
        "sku_unique = sku_df.drop_duplicates(subset=[\"Article No\", \"Colour Code\"])\n",
        "\n",
        "# ==== STEP 6: Merge with Image Files ====\n",
        "merged = (\n",
        "    images_df\n",
        "    .merge(sku_unique[[\"Article No\", \"Color\", \"Colour Code\"]], on=[\"Article No\", \"Colour Code\"], how=\"left\")\n",
        "    .merge(article_dim, on=\"Article No\", how=\"left\")\n",
        ")\n",
        "\n",
        "# Optional: Map View No to readable label\n",
        "view_map = {\"1\": \"Front View\", \"2\": \"Side View\", \"3\": \"Back View\"}\n",
        "merged[\"View Description\"] = merged[\"View No\"].map(view_map)\n",
        "\n",
        "# Empty column for next stage\n",
        "merged[\"AI Prompt\"] = \"\"\n",
        "\n",
        "from openai import OpenAI\n",
        "import base64\n",
        "import os\n",
        "\n",
        "# Replace with your own key\n",
        "client = OpenAI(api_key=\"INSERT CHAT GPT API\")\n",
        "\n",
        "def encode_image(image_path):\n",
        "    with open(image_path, \"rb\") as img_file:\n",
        "        return base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
        "\n",
        "merged[\"Dimensions\"] = merged.apply(\n",
        "    lambda row: f\"{round(row['Height (cm)']/10, 1)}cm (H) x {round(row['Width (cm)']/10, 1)}cm (W) x {round(row['Depth (cm)']/10, 1)}cm (D)\",\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "def gpt_caption(image_path, prompt=\"Describe this fashion bag‚Äôs color, shape, material, and design details. Mention hardware or structure if visible.\"):\n",
        "    base64_image = encode_image(image_path)\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": [\n",
        "                {\"type\": \"text\", \"text\": prompt},\n",
        "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
        "            ]}\n",
        "        ],\n",
        "        max_tokens=200\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "test_df = merged.head(16).copy()\n",
        "\n",
        "test_df[\"AI_Description\"] = test_df.apply(\n",
        "    lambda row: gpt_caption(\n",
        "        f\"images/{row['Image File']}\",\n",
        "        prompt=(\n",
        "            f\"Describe this fashion bag using industry terms. Include:\\n\"\n",
        "            f\"- Color: {row['Color']}\\n\"\n",
        "            f\"- Shape/silhouette\\n\"\n",
        "            f\"- Material (if visible)\\n\"\n",
        "            f\"- Handle or strap type\\n\"\n",
        "            f\"- Any visible details (e.g. quilting, buckles, metalwork)\\n\"\n",
        "            f\"- Use these measurements: {row['Dimensions']}.\\n\"\n",
        "            f\"Return one coherent sentence.\"\n",
        "        )\n",
        "    ),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "merged[\"Dimensions\"] = merged.apply(\n",
        "    lambda row: f\"{int(row['Height (cm)'])}cm (H) x {int(row['Width (cm)'])}cm (W) x {int(row['Depth (cm)'])}cm (D)\",\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Caption each image using GPT-4 Vision\n",
        "test_df[\"AI_Description\"] = test_df[\"Image File\"].apply(lambda fname: gpt_caption(f\"images/{fname}\"))\n",
        "\n",
        "# Export results\n",
        "test_df.to_csv(\"Preprocessed_with_AI_Descriptions.csv\", index=False)\n",
        "from google.colab import files\n",
        "files.download(\"Preprocessed_with_AI_Descriptions.csv\")\n",
        "\n",
        "merged[\"AI_Description\"] = merged.apply(\n",
        "    lambda row: gpt_caption(\n",
        "        f\"images/{row['Image File']}\",\n",
        "        prompt=(\n",
        "            f\"Describe this fashion bag using industry terms. Include:\\n\"\n",
        "            f\"- Color: {row['Color']}\\n\"\n",
        "            f\"- Shape/silhouette\\n\"\n",
        "            f\"- Material (if visible)\\n\"\n",
        "            f\"- Handle or strap type\\n\"\n",
        "            f\"- Any visible details (e.g. quilting, buckles, metalwork)\\n\"\n",
        "            f\"- Use these measurements: {row['Dimensions']}.\\n\"\n",
        "            f\"Return one coherent sentence.\"\n",
        "        )\n",
        "    ),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# ==== STEP 7: Export Final CSV ====\n",
        "output_name = \"Preprocessed_Bag_Metadata.csv\"\n",
        "merged.to_csv(output_name, index=False)\n",
        "files.download(output_name)\n",
        "\n",
        "print(\"‚úÖ Done! Clean CSV generated and downloading.\")"
      ],
      "metadata": {
        "id": "Eh2Pq12bFV0h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}